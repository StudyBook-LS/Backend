{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Study categorization with scispacy.\n",
    "\n",
    "Import the things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scispacy\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/83/1b0b2d639c6736acedb738e393ad4566302a88a39b44e792fd98a0137c61/scispacy-0.2.3-py3-none-any.whl\n",
      "Collecting nmslib>=1.7.3.6 (from scispacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/4d/4d110e53ff932d7a1ed9c2f23fe8794367087c29026bf9d4b4d1e27eda09/nmslib-1.8.1.tar.gz (261kB)\n",
      "\u001b[K     |████████████████████████████████| 266kB 476kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn>=0.20.3 (from scispacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/57/8a9889d49d0d77905af5a7524fb2b468d2ef5fc723684f51f5ca63efed0d/scikit_learn-0.21.3-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (10.5MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5MB 156kB/s eta 0:00:01    |▌                               | 174kB 537kB/s eta 0:00:20\n",
      "\u001b[?25hCollecting awscli (from scispacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/5f/f055086d586aa4574874d1d1317e1036f08709a22992323067a775c71b6a/awscli-1.16.250-py2.py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 202kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting conllu (from scispacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/34/ddfbf22e7477a75ca609d60a831452439383e4ab61bed2b5a1b83d1eef5b/conllu-2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: spacy>=2.1.3 in /anaconda3/lib/python3.7/site-packages (from scispacy) (2.1.4)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from scispacy) (1.15.4)\n",
      "Requirement already satisfied: joblib in /anaconda3/lib/python3.7/site-packages (from scispacy) (0.13.2)\n",
      "Collecting pybind11>=2.0 (from nmslib>=1.7.3.6->scispacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c1/0b28ec6f7d0151eebd36c66d3c7dbaa82b5006cc9d25980b5b56cf1034f1/pybind11-2.4.2-py2.py3-none-any.whl (149kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 192kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.20.3->scispacy) (1.1.0)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /anaconda3/lib/python3.7/site-packages (from awscli->scispacy) (0.2.1)\n",
      "Requirement already satisfied: PyYAML<=5.2,>=3.10; python_version != \"2.6\" in /anaconda3/lib/python3.7/site-packages (from awscli->scispacy) (3.13)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /anaconda3/lib/python3.7/site-packages (from awscli->scispacy) (0.14)\n",
      "Collecting rsa<=3.5.0,>=3.1.2 (from awscli->scispacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 167kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: colorama<=0.3.9,>=0.2.5 in /anaconda3/lib/python3.7/site-packages (from awscli->scispacy) (0.3.9)\n",
      "Collecting botocore==1.12.240 (from awscli->scispacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/74/270e183247b27572e65465c840c739d2b6532e88541bd53e762732880667/botocore-1.12.240-py2.py3-none-any.whl (5.7MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7MB 328kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (2.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (2.0.1)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (7.0.4)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (0.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (2.20.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (0.2.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (2.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (0.0.7)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /anaconda3/lib/python3.7/site-packages (from spacy>=2.1.3->scispacy) (0.9.6)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<=3.5.0,>=3.1.2->awscli->scispacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/71/8f0d444e3a74e5640a3d5d967c1c6b015da9c655f35b2d308a55d907a517/pyasn1-0.4.7-py2.py3-none-any.whl (76kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 455kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /anaconda3/lib/python3.7/site-packages (from botocore==1.12.240->awscli->scispacy) (1.25.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda3/lib/python3.7/site-packages (from botocore==1.12.240->awscli->scispacy) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /anaconda3/lib/python3.7/site-packages (from botocore==1.12.240->awscli->scispacy) (2.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /anaconda3/lib/python3.7/site-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.3->scispacy) (4.28.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.3->scispacy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.3->scispacy) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.3->scispacy) (2018.11.29)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore==1.12.240->awscli->scispacy) (1.12.0)\n",
      "Building wheels for collected packages: nmslib\n",
      "  Building wheel for nmslib (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /anaconda3/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T/pip-install-scb1e0j2/nmslib/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T/pip-install-scb1e0j2/nmslib/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T/pip-wheel-82ovc6yu --python-tag cp37\n",
      "       cwd: /private/var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T/pip-install-scb1e0j2/nmslib/\n",
      "  Complete output (24 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  creating var\n",
      "  creating var/folders\n",
      "  creating var/folders/kj\n",
      "  creating var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn\n",
      "  creating var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/anaconda3/include -arch x86_64 -I/anaconda3/include -arch x86_64 -I/anaconda3/include/python3.7m -c /var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T/tmpurcyoumi.cpp -o var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T/tmpurcyoumi.o -std=c++14\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/anaconda3/include -arch x86_64 -I/anaconda3/include -arch x86_64 -I/anaconda3/include/python3.7m -c /var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T/tmph7lffirl.cpp -o var/folders/kj/qqdtl86s5kjdck2yy_27_rtw0000gn/T/tmph7lffirl.o -fvisibility=hidden\n",
      "  building 'nmslib' extension\n",
      "  creating build\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7/nmslib\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7/nmslib/similarity_search\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7/nmslib/similarity_search/src\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7/nmslib/similarity_search/src/space\n",
      "  creating build/temp.macosx-10.7-x86_64-3.7/nmslib/similarity_search/src/method\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/anaconda3/include -arch x86_64 -I/anaconda3/include -arch x86_64 -I./nmslib/similarity_search/include -I/anaconda3/include -I/anaconda3/include -I/anaconda3/include -I/anaconda3/include -I/anaconda3/lib/python3.7/site-packages/numpy/core/include -I/anaconda3/include/python3.7m -c nmslib.cc -o build/temp.macosx-10.7-x86_64-3.7/nmslib.o -O3 -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DVERSION_INFO=\"1.8.1\" -std=c++14 -fvisibility=hidden\n",
      "  nmslib.cc:16:10: fatal error: 'pybind11/pybind11.h' file not found\n",
      "  #include <pybind11/pybind11.h>\n",
      "           ^~~~~~~~~~~~~~~~~~~~~\n",
      "  1 error generated.\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for nmslib\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for nmslib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build nmslib\n",
      "\u001b[31mERROR: awsebcli 3.15.2 has requirement six<1.12.0,>=1.11.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: awsebcli 3.15.2 has requirement urllib3<1.25,>=1.24.1, but you'll have urllib3 1.25.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pybind11, nmslib, scikit-learn, pyasn1, rsa, botocore, awscli, conllu, scispacy\n",
      "  Running setup.py install for nmslib ... \u001b[?25ldone\n",
      "\u001b[?25h  Found existing installation: scikit-learn 0.20.1\n",
      "    Uninstalling scikit-learn-0.20.1:\n",
      "      Successfully uninstalled scikit-learn-0.20.1\n",
      "  Found existing installation: botocore 1.12.199\n",
      "    Uninstalling botocore-1.12.199:\n",
      "      Successfully uninstalled botocore-1.12.199\n",
      "Successfully installed awscli-1.16.250 botocore-1.12.240 conllu-2.0 nmslib-1.8.1 pyasn1-0.4.7 pybind11-2.4.2 rsa-3.4.2 scikit-learn-0.21.3 scispacy-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stopwords\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/a2/d4eb1d5e609fa0b1d59e929db8eb9ae540f8b2d6db3a4ba26f713e81af15/stopwords-0.1.3.tar.gz (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 213kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: stopwords\n",
      "  Building wheel for stopwords (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for stopwords: filename=stopwords-0.1.3-py2.py3-none-any.whl size=37286 sha256=269877e7b33ba8f86e2bb6827ba0881fb89a902d56c5f8b5ac47c635350dea71\n",
      "  Stored in directory: /Users/connorheraty/Library/Caches/pip/wheels/39/fa/c7/c4c5111e658f5c58465d948165dc3395a3c10ff57f4cd20356\n",
      "Successfully built stopwords\n",
      "Installing collected packages: stopwords\n",
      "Successfully installed stopwords-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(lang)? (__init__.py, line 84)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3267\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-af8a71248fef>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from stopwords import STOPWORDS\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/anaconda3/lib/python3.7/site-packages/stopwords/__init__.py\"\u001b[0;36m, line \u001b[0;32m84\u001b[0m\n\u001b[0;31m    print lang\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(lang)?\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import multiprocessing\n",
    "import pprint\n",
    "import re\n",
    "import spacy\n",
    "import scispacy\n",
    "import sys\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from stopwords import STOPWORDS\n",
    "from tqdm import tqdm_notebook\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "\n",
      "\u001b[38;5;1m✘ No compatible model found for 'en_core_sci_lg' (spaCy v2.1.4).\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_sci_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up scispacy with additional stopwords, abbreviation detection and entity detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_sci_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c99f7e1dab73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_sci_lg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mSTOPWORDS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mabbreviation_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbbreviationDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_sci_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "\n",
    "nlp.Defaults.stop_words |= STOPWORDS\n",
    "\n",
    "abbreviation_pipe = AbbreviationDetector(nlp)\n",
    "nlp.add_pipe(abbreviation_pipe)\n",
    "\n",
    "linker = UmlsEntityLinker(resolve_abbreviations=True,\n",
    "                         k=10,\n",
    "                         max_entities_per_mention=3)\n",
    "nlp.add_pipe(linker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure hashability for faster lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7b87a310207e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstopwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "stopwords = dict()\n",
    "for word in nlp.Defaults.stop_words:\n",
    "    stopwords[word] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define import functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def replace_csv_missing(row):\n",
    "    \"\"\"Do basic text cleaning from csv rows.\"\"\"\n",
    "    text = (row[0] + ' ' + \n",
    "            row[1] + ' ' + \n",
    "            row[8] + ' ' + \n",
    "            ', '.join(row[2].split()) + ', ' + \n",
    "            ', '.join(row[3].split()) + ', ' + \n",
    "            ', '.join(row[6].split()) + ', ' + \n",
    "            ', '.join(row[7].split())\n",
    "           )\n",
    "    new = re.sub('missing', '', text)\n",
    "    new = re.sub('-', ' ', new)\n",
    "    new = re.sub('\\(\\S*\\)', ' ', new)\n",
    "    new = re.sub(' \\s+', ' ', new)\n",
    "    new = re.sub(',,', ',', new)\n",
    "    return u\"{}\".format(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_files(file):\n",
    "    all_rows = []\n",
    "    with open(file, 'r') as csvinfile:\n",
    "        csv_reader = csv.reader(csvinfile, delimiter=',')\n",
    "#         for row in csv_reader:\n",
    "#             all_rows.append(row)\n",
    "        # Size limit for development.\n",
    "        for i, row in enumerate(csv_reader):\n",
    "            if i > 1000:\n",
    "                break\n",
    "            all_rows.append(row)\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "    with pool as p:\n",
    "        transformed_rows = p.map(replace_csv_missing, all_rows)\n",
    "    return transformed_rows\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms = import_csv_files('../all_trials_text.csv')[1:]  # Discard header row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll need a place to store our index for fast lookup. [This](https://aws.amazon.com/blogs/aws/amazon-dynamodb-internet-scale-data-storage-the-nosql-way/) looks promising.\n",
    "\n",
    "below is a json like idea that we should be able to upload to a db easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_entry(entry: str, index: int, dictionary: defaultdict) -> None:\n",
    "    \"\"\"Make an index entry with look-up terms as keys, tuples of document indexes and\n",
    "    relevancy score as values.\n",
    "    \n",
    "    :var entry: text from which terms are to be extracted.\n",
    "    :var index: index of text\n",
    "    :var dictionary: dictionary to update with new terms and indexes.\n",
    "    \"\"\"\n",
    "    doc = nlp(entry)\n",
    "    count = Counter()\n",
    "    for text in doc.ents:\n",
    "        if text.lemma_.lower() not in stopwords:\n",
    "            count[text.lemma_.lower()] += 1\n",
    "    total = sum(count.values())\n",
    "    for term, relevancy in count.items():\n",
    "        dictionary[term].update({index: round(relevancy / total, 4)})\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(corpus: list) -> defaultdict:\n",
    "    \"\"\"Create a dict index of look-up terms.\n",
    "    \n",
    "    Look-up terms as keys, tuples of document indexes and\n",
    "    relevancy scores as values.\n",
    "    \n",
    "    :var corpus: list of list of strings from which to extract look-up terms.\n",
    "    \n",
    "    :returns dictionary: dict of dicts \"look-up term\": {index: relevancy score},\n",
    "    \"\"\"\n",
    "    dictionary = defaultdict(dict)\n",
    "    for i, text in tqdm_notebook(enumerate(corpus)):\n",
    "        make_entry(text, i, dictionary)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664e8f9bf9274bb99b6327a2717f0bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = create_index(search_terms)\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for display purposes. Just the entries ending in 'a'.\n",
    "filtered_index = dict(filter(lambda item: item[0].endswith('a'), index.items()))\n",
    "print(len(filtered_index))\n",
    "pprint.pprint(filtered_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
