{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Perceptron on XOR Gates](#Q2)\n",
    "3. [Multilayer Perceptron](#Q3)\n",
    "4. [Keras MMP](#Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** \n",
    "    The base unit for a network. Applies weights and biases to inputs, then an activatin function before passing info \n",
    "    to the next level.\n",
    "- **Input Layer:** \n",
    "    The layer that takes in the data from the dataset.\n",
    "- **Hidden Layer:** \n",
    "    Layers between the input and output layers.\n",
    "- **Output Layer:**\n",
    "    The final layer. This is where the prediction is made.\n",
    "- **Activation:**\n",
    "    A function applied to the result of multiplying input by weight and adding bias. Determines if node 'fires' and at what degree.\n",
    "- **Backpropagation:**\n",
    "    A function for updating weights and biases at the beginning of the network based off of the last iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perceptron on XOR Gates <a id=\"Q2\"></a>\n",
    "\n",
    "The XOr, or “exclusive or”, problem is a classic problem in ANN research. It is the problem of using a neural network to predict the outputs of XOr logic gates given two binary inputs. An XOr function should return a true value if the two inputs are not equal and a false value if they are equal. Create a perceptron class that can model the behavior of an AND gate. You can use the following table as your training data:\n",
    "\n",
    "|x1\t|x2 | y |\n",
    "|---|---|---|\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 1 | 0 |\n",
    "| 1 | 0 | 1 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \"\"\"Perceptron estimator with early stopping.\n",
    "    \n",
    "    :param learning_rate: float Estimator learning rate. Default == 0.01\n",
    "    :param epochs: int Number of epochs to run Perceptron. Default = 1000\n",
    "    :param early_stopping: int Number of epochs without imoprovement at which to stop estimator. Default = 10\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, epochs=100, early_stopping=10):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping = early_stopping\n",
    "        \n",
    "    def predict(self,row):\n",
    "        \"\"\"Apply weights and add bias to inputs.\n",
    "        \n",
    "        Return 1 if output is greater or equal zero, else zero for each element in input row.\n",
    "        \"\"\"\n",
    "        \n",
    "        return (np.dot(row, self.weight[1:]) + self.weight[0]) >= 0\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data\n",
    "        \n",
    "        Initialize with random bias and weights.\n",
    "        Update weights and bias with each row based on previous iteration's error.\n",
    "        Store number of errors for each epoch.\n",
    "        Stop if no errors in number of `early_stopping` epochs.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.weight = np.array([np.random.random() for _ in range(X.shape[1] + 1)])\n",
    "    \n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            error = 0\n",
    "            for row, label in zip(X, y):\n",
    "                \n",
    "                # Check our current prediction against the actual label to get the error.\n",
    "                # Multiply the result by the learning rate.\n",
    "                adjustment = self.lr * (label - self.predict(row))\n",
    "                \n",
    "                # Adjust our weigts and bias accordingly.\n",
    "                self.weight[1:] += adjustment * row\n",
    "                self.weight[0] += adjustment\n",
    "                \n",
    "                # Add up our errors for each epoch.\n",
    "                error += adjustment != 0.0\n",
    "                \n",
    "            # Make a list of number of errors per epoch.\n",
    "            self.errors_.append(error)\n",
    "\n",
    "            # If we've been correct each time for a number of rounds, stop already.\n",
    "            if sum(self.errors_[-self.early_stopping:]) == 0:\n",
    "#                 print('Stopped Early')\n",
    "                break\n",
    "                \n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoublePerceptron(object):\n",
    "    \"\"\"Combines output of two Perceptrons as input to a final Perceptron.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.perc = Perceptron()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit two Perceptrons to the data, zip outputs together to use as input\n",
    "        for self.perc.\n",
    "        \"\"\"\n",
    "        self.one = Perceptron().fit(X, y)\n",
    "        self.two = Perceptron().fit(X, y)\n",
    "        first = self.one.predict(X)\n",
    "        second = self.two.predict(X)\n",
    "        inputs = np.array([np.array([one, two]) for one, two in zip(first, second)])\n",
    "        self.perc.fit(inputs, y)\n",
    "        \n",
    "    def _predict(self, X):\n",
    "        \"\"\"Use predictions from self.one and self.two to predict yhat from X.\"\"\"\n",
    "        first = self.one.predict(X)\n",
    "        second = self.two.predict(X)\n",
    "\n",
    "        try:\n",
    "            inputs = np.array([np.array([one, two]) for one, two in zip(first, second)])\n",
    "        except TypeError as e:\n",
    "            inputs = np.array([first, second])\n",
    "        return self.perc.predict(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor = DoublePerceptron()\n",
    "\n",
    "Xor = np.array([np.array([0, 0]),\n",
    "                np.array([1, 0]),\n",
    "                np.array([0, 1]),\n",
    "                np.array([1, 1])])\n",
    "\n",
    "yor = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "xor.fit(Xor, yor)\n",
    "\n",
    "xor._predict(np.array([np.array([1, 0]),\n",
    "                      np.array([1, 1]),\n",
    "                      np.array([0, 1]), \n",
    "                      np.array([0, 0])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights.\n",
    "Your network must have one hidden layer.\n",
    "You do not have to update weights via gradient descent. You can use something like the derivative of the sigmoid function to update weights.\n",
    "Train your model on the Heart Disease dataset from UCI:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "177   64    1   2       140   335    0        1      158      0      0.0   \n",
       "41    48    1   1       130   245    0        0      180      0      0.2   \n",
       "117   56    1   3       120   193    0        0      162      0      1.9   \n",
       "279   61    1   0       138   166    0        0      125      1      3.6   \n",
       "203   68    1   2       180   274    1        0      150      1      1.6   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "177      2   0     2       0  \n",
       "41       1   0     2       1  \n",
       "117      1   0     3       1  \n",
       "279      1   1     2       0  \n",
       "203      1   0     3       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='target').values\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (303,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    \n",
    "    def __init__(self, epochs=10000, learning_rate=0.01, n_input=13, n_hidden=64, n_out=1):\n",
    "        \n",
    "        # Initialize hyperparameter variables.\n",
    "        self.epochs = epochs\n",
    "        self.lr = learning_rate\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "    \n",
    "        # Initialize weights and biases.\n",
    "        self.hidden_weight = np.random.random(size=(self.n_input + 1, self.n_hidden))\n",
    "        self.output_weight = np.random.random(size=(self.n_hidden + 1, self.n_out))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_prime(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.errors = []\n",
    "        for i in range(self.epochs):\n",
    "            out = self.predict(X)\n",
    "            self.backpass(X, y, out)\n",
    "        print(f'Training error at {i} epoch: {self.errors[-1]}')\n",
    "\n",
    "    def backpass(self, X, y, out):\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        error = y - out\n",
    "        \n",
    "        self.errors.append(np.sum(error**2))\n",
    "        # Caluculate adjustment from hidden -> output.\n",
    "        delta_output = self.sigmoid_prime(out) * error\n",
    "        \n",
    "        # Calculate error from input -> hidden.\n",
    "        output_error = delta_output.dot(self.output_weight[1:].T)\n",
    "        delta_hidden = output_error * self.sigmoid_prime(out)\n",
    "        \n",
    "        #Adjust hidden -> output weghts.\n",
    "\n",
    "        self.output_weight[1:] += self.activated_hidden.T.dot(delta_output) * self.lr\n",
    "        self.output_weight[0] = np.sum(delta_output)\n",
    "\n",
    "        self.hidden_weight[1:] += X.T.dot(delta_hidden) * self.lr\n",
    "        self.hidden_weight[0] = np.sum(delta_hidden)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        inputs = np.dot(X, self.hidden_weight[1:]) + self.hidden_weight[0]\n",
    "        self.activated_hidden = self.sigmoid(inputs)\n",
    "        output = np.dot(self.activated_hidden, self.output_weight[1:]) + self.output_weight[0]\n",
    "        final = self.sigmoid(output)\n",
    "        return final\n",
    "        \n",
    "    def plot_error(self):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title('Training Error')\n",
    "        plt.plot(self.errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "better = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error at 9999 epoch: 31.431730916685027\n"
     ]
    }
   ],
   "source": [
    "better.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82827137])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better.predict([37, 1, 2, 130, 250, 0, 1, 187, 0, 3.5, 0, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82827138])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better.predict([56, 1, 1, 120, 236, 0, 1, 178, 0, 0.8, 2, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82827151])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "better.predict([63, 0, 0, 108, 269, 0, 1, 169, 1, 1.8, 1, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras MMP <a id=\"Q4\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 5 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creator(optimizer='adam', learning_rate=.01):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_dim=inputs))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(learning_rate=learning_rate, loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=model_creator, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = X.T, y.T\n",
    "\n",
    "inputs = X.shape[1]\n",
    "epochs = 20\n",
    "batch_size = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': [10, 50, 100, 250, 500, 1000, 2500],\n",
    "          'epochs': [20]}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=2)\n",
    "grid_result = grid.fit(X, y)\n",
    "print(f'Best: {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'Mean: {mean}, Stdev: {stdev} with : {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'optimizer': ['adam', 'adagrad', 'sgd'],\n",
    "          'epochs': [20]}\n",
    "grid1 = GridSearchCV(estimator=grid_result.best_estimator_, param_grid= params,\n",
    "                   n_jobs=-1)\n",
    "grid_result1 = grid1.fit(X, y, verbose=1)\n",
    "\n",
    "print(f'Best: {grid_result1.best_score_} using {grid_result1.best_params_}')\n",
    "means = grid_result1.cv_results_['mean_test_score']\n",
    "stds = grid_result1.cv_results_['std_test_score']\n",
    "params = grid_result1.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f'Mean: {mean}, Stdev: {stdev} with : {param}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3.7 (unit4wk2)",
   "language": "python",
   "name": "unit4wk2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
